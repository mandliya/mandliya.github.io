{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ada770966234be9a30bc14dd4bfb69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_167492abf8104764b72aa13c53ffe7d7",
              "IPY_MODEL_665bb838f9274e80b9350c6ab48585ee",
              "IPY_MODEL_95eef6921a394806b0af5656b954f1b7"
            ],
            "layout": "IPY_MODEL_9fb7f93f4d3945c98c9ca4cef1f94687"
          }
        },
        "167492abf8104764b72aa13c53ffe7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3720f17136439fb2ca73ae7b1ca4eb",
            "placeholder": "​",
            "style": "IPY_MODEL_941b595afde9440f92d62c2ea9f67f8c",
            "value": "README.md: "
          }
        },
        "665bb838f9274e80b9350c6ab48585ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111008e8ab1c4dfc849e4d4ae8075acd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_341a9e54bff843a6b466f438515c41e8",
            "value": 1
          }
        },
        "95eef6921a394806b0af5656b954f1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8f1b74cac24f55af2c225ccaf187f5",
            "placeholder": "​",
            "style": "IPY_MODEL_f30363e74aa74636afb31fb606e9d5c3",
            "value": " 1.06k/? [00:00&lt;00:00, 119kB/s]"
          }
        },
        "9fb7f93f4d3945c98c9ca4cef1f94687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3720f17136439fb2ca73ae7b1ca4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941b595afde9440f92d62c2ea9f67f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111008e8ab1c4dfc849e4d4ae8075acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "341a9e54bff843a6b466f438515c41e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b8f1b74cac24f55af2c225ccaf187f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30363e74aa74636afb31fb606e9d5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandliya/mandliya.github.io/blob/main/parked/gpt_2_complete_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EwTaUzOqQKlS"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets jaxtyping tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from jaxtyping import Float, Int\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import tiktoken\n",
        "from datasets import load_dataset\n",
        "from google.colab import userdata\n",
        "import pathlib\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "va8s9t4CQUnK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GPT2Config:\n",
        "  n_layers: int = 12\n",
        "  d_model: int = 768\n",
        "  n_heads: int = 12\n",
        "  vocab_size: int = 50257\n",
        "  layer_norm_eps: float = 1e-5\n",
        "  init_range: float = 0.02\n",
        "  dropout: float = 0.1\n",
        "  n_ctx: int = 1024\n",
        "  d_mlp: int = 4 * 768\n",
        "  weight_tying: bool = True"
      ],
      "metadata": {
        "id": "IRGRW3jhQfhv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Attention(nn.Module):\n",
        "  def __init__(self, cfg: GPT2Config):\n",
        "    super().__init__()\n",
        "    assert cfg.d_model % cfg.n_heads == 0, (\n",
        "        f\"{cfg.d_model} should be divisible by {cfg.n_heads}\"\n",
        "    )\n",
        "    self.cfg = cfg\n",
        "    self.c_attn = nn.Linear(cfg.d_model, 3 * cfg.d_model)\n",
        "    self.attn_dropout = nn.Dropout(cfg.dropout)\n",
        "    self.c_proj = nn.Linear(cfg.d_model, cfg.d_model)\n",
        "    self.resid_dropout = nn.Dropout(cfg.dropout)\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.tril(torch.ones(cfg.n_ctx, cfg.n_ctx))\n",
        "        .view(1, 1, cfg.n_ctx, cfg.n_ctx)\n",
        "    )\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      x: Float[Tensor, \"B T d_model\"]) -> Float[Tensor, \"B T d_model\"]:\n",
        "      B, T, d_model = x.shape\n",
        "      n_heads = self.cfg.n_heads\n",
        "      d_head = d_model // n_heads\n",
        "      qkv = self.c_attn(x) #[B, T, d_model * 3]\n",
        "      q, k, v = qkv.split(d_model, dim=2)\n",
        "      q = q.view(B, T, n_heads, d_head).transpose(1, 2) #[B nh T dh]\n",
        "      k = k.view(B, T, n_heads, d_head).transpose(1, 2)\n",
        "      v = v.view(B, T, n_heads, d_head).transpose(1, 2)\n",
        "\n",
        "      attn = q @ k.transpose(-2, -1) * (1.0 / math.sqrt(d_head))\n",
        "      attn = attn.masked_fill(\n",
        "          self.mask[:, :, :T, :T] == 0,\n",
        "          float('-inf')\n",
        "      )\n",
        "      attn = attn.softmax(dim=-1)\n",
        "      attn = self.attn_dropout(attn)\n",
        "      out = attn @ v #[B, nh, T, dh]\n",
        "      out = out.transpose(1, 2).contiguous().view(B, T, d_model)\n",
        "      out = self.c_proj(out)\n",
        "      return self.resid_dropout(out)"
      ],
      "metadata": {
        "id": "G8KS-oCpQ1qk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2MLP(nn.Module):\n",
        "  def __init__(self, cfg: GPT2Config):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.c_fc = nn.Linear(cfg.d_model, cfg.d_mlp)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.c_proj = nn.Linear(cfg.d_mlp, cfg.d_model)\n",
        "    self.dropout = nn.Dropout(cfg.dropout)\n",
        "\n",
        "  def forward(self, x: Float[Tensor, \"B T d_model\"]) -> Float[Tensor, \"B T d_model\"]:\n",
        "    x = self.c_fc(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.c_proj(x)\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "id": "o3LR0-yfS8Jw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Block(nn.Module):\n",
        "  def __init__(self, cfg: GPT2Config):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.ln_1 = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
        "    self.attn = GPT2Attention(cfg)\n",
        "    self.ln_2 = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
        "    self.mlp = GPT2MLP(cfg)\n",
        "\n",
        "  def forward(self, x: Float[Tensor, \"B T d_model\"]) -> Float[Tensor, \"B T d_model\"]:\n",
        "    x = x + self.attn(self.ln_1(x))\n",
        "    x = x + self.mlp(self.ln_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "d_7pqjn_TePj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Model(nn.Module):\n",
        "  def __init__(self, cfg: GPT2Config):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.transformer = nn.ModuleDict(dict(\n",
        "        wte = nn.Embedding(cfg.vocab_size, cfg.d_model),\n",
        "        wpe = nn.Embedding(cfg.n_ctx, cfg.d_model),\n",
        "        embd_dropout = nn.Dropout(cfg.dropout),\n",
        "        h = nn.ModuleList([\n",
        "            GPT2Block(cfg) for _ in range(self.cfg.n_layers)\n",
        "        ]),\n",
        "        ln_f = nn.LayerNorm(cfg.d_model, eps=cfg.layer_norm_eps)\n",
        "    ))\n",
        "    self.lm_head = nn.Linear(cfg.d_model, cfg.vocab_size)\n",
        "    if cfg.weight_tying:\n",
        "      self.lm_head.weight = self.transformer.wte.weight\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "    for np, p in self.named_parameters():\n",
        "      if np.endswith('c_proj.weight'):\n",
        "        nn.init.normal_(p, mean=0.0, std=(cfg.init_range/math.sqrt(2 * cfg.n_layers)))\n",
        "\n",
        "  def _init_weights(self, module: nn.Module):\n",
        "    if isinstance(module, nn.Linear):\n",
        "      nn.init.normal_(module.weight, mean=0.0, std=self.cfg.init_range)\n",
        "      if module.bias is None:\n",
        "        nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "      nn.init.normal_(module.weight, mean=0.0, std=self.cfg.init_range)\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      tokens: Int[Tensor, \"B T\"],\n",
        "      targets: Optional[Int[Tensor, \"B T\"]]\n",
        "    ) -> Tuple[Int[Tensor, \"B T vocab_size\"], Float[Tensor, \"\"]]:\n",
        "    B, T = tokens.shape\n",
        "    assert T <= self.cfg.n_ctx, (\n",
        "        f\"Sequence length {T} is longer than max sequence length: {self.cfg.n_ctx}\"\n",
        "    )\n",
        "    tok_emb = self.transformer.wte(tokens)\n",
        "    pos = torch.arange(0, T, dtype=torch.long, device=tokens.device)\n",
        "    pos_emb = self.transformer.wpe(pos)\n",
        "    residual = pos_emb + tok_emb\n",
        "    residual = self.transformer.embd_dropout(residual)\n",
        "    for block in self.transformer.h:\n",
        "      residual = block(residual)\n",
        "\n",
        "    residual = self.transformer.ln_f(residual)\n",
        "    if targets is not None:\n",
        "      logits = self.lm_head(residual) #[B T vocab_size]\n",
        "      loss = F.cross_entropy(\n",
        "          logits.view(-1, logits.size(-1)), #[B*T vocab_size]\n",
        "          targets.view(-1), #[B * T]\n",
        "          ignore_index=-1\n",
        "      )\n",
        "    else:\n",
        "      logits = self.lm_head(residual[:, [-1], :]) #[B 1 vocab_size]\n",
        "      loss = None\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def generate(\n",
        "      self,\n",
        "      tokens: Int[Tensor, \"B T\"],\n",
        "      temperature: float = 1.0,\n",
        "      max_num_tokens: int = 256,\n",
        "      top_k: Optional[int] = None\n",
        "    ) -> Int[Tensor, \"B T+max_num_tokens\"]:\n",
        "    for _ in range(max_num_tokens):\n",
        "      tok_cond = (\n",
        "          tokens\n",
        "          if tokens.size(-1) <= self.cfg.n_ctx\n",
        "          else tokens[:, -self.cfg.n_ctx:]\n",
        "      )\n",
        "      logits, _ = self(tok_cond, targets=None) #[B T vocab_size]\n",
        "      logits = logits[:, -1, :] #[B vocab_size]\n",
        "      logits = logits / temperature\n",
        "      if top_k is not None:\n",
        "        k = min(k, self.cfg.vocab_size)\n",
        "        v, _ = torch.topk(logits, k) #[B k]\n",
        "        threshold = v[:, [-1]] #[B, 1]\n",
        "        logits.masked_fill_(logits < threshold, float('-inf'))\n",
        "      probs = logits.softmax(dim=-1) #[B vocab_size]\n",
        "      next_token = torch.multinomial(probs, num_samples=1) #[B, 1]\n",
        "      tokens = torch.cat((tokens, next_token), dim=1)\n",
        "    return tokens\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9cJCK-ElUFKD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, I am a large language model.\" * 500\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "tokens = enc.encode(text)\n",
        "tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "print(f'Total tokens: {len(tokens)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL97nWzEXGfA",
        "outputId": "c1acae52-3afd-4c33-a747-0f63707c0100"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(tokens: Tensor, block_size: int, batch_size: int, device: str):\n",
        "  idx = torch.randint(0, len(tokens)-block_size, (batch_size,))\n",
        "  x = torch.stack([tokens[i: i+block_size] for i in idx])\n",
        "  y = torch.stack([tokens[i+1: i+block_size+1] for i in idx])\n",
        "  return x.to(device), y.to(device)"
      ],
      "metadata": {
        "id": "lmhBYy5MZI6x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cfg = GPT2Config(dropout=0)\n",
        "model = GPT2Model(cfg)\n",
        "model = model.to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
        "steps = 200\n",
        "for step in range(steps):\n",
        "  x, y = get_batch(tokens, block_size=cfg.n_ctx, batch_size=2, device=device)\n",
        "  optimizer.zero_grad()\n",
        "  _, loss = model(x, targets=y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if step % 10 == 0:\n",
        "    print(f'{step=:4} | Loss: {loss.item():.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys4jfsRhZpAr",
        "outputId": "9e86d393-8993-4457-876f-b3de6fa011b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step=   0 | Loss: 11.091410\n",
            "step=  10 | Loss: 5.922181\n",
            "step=  20 | Loss: 5.396425\n",
            "step=  30 | Loss: 5.022036\n",
            "step=  40 | Loss: 4.661715\n",
            "step=  50 | Loss: 4.316027\n",
            "step=  60 | Loss: 3.979648\n",
            "step=  70 | Loss: 3.658325\n",
            "step=  80 | Loss: 3.350863\n",
            "step=  90 | Loss: 3.031948\n",
            "step= 100 | Loss: 2.147627\n",
            "step= 110 | Loss: 1.343678\n",
            "step= 120 | Loss: 0.310863\n",
            "step= 130 | Loss: 0.093907\n",
            "step= 140 | Loss: 0.061922\n",
            "step= 150 | Loss: 0.048684\n",
            "step= 160 | Loss: 0.039142\n",
            "step= 170 | Loss: 0.033269\n",
            "step= 180 | Loss: 0.029778\n",
            "step= 190 | Loss: 0.025852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = userdata.get('HF_TOKEN')\n"
      ],
      "metadata": {
        "id": "sCtFAtykh0rN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DatasetConfig:\n",
        "  out_dir: str = './data'\n",
        "  write_batch_size: int = 128\n",
        "  hf_dataset:str = 'roneneldan/TinyStories'\n",
        "  max_examples: int = 600000\n",
        "  n_ctx: int = 1024"
      ],
      "metadata": {
        "id": "HMdRz5as5-8s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretokenize_and_save(config: DatasetConfig, split='train'):\n",
        "  dataset = load_dataset(\n",
        "      config.hf_dataset,\n",
        "      split=split,\n",
        "      streaming=True,\n",
        "  )\n",
        "  enc = tiktoken.get_encoding('gpt2')\n",
        "  os.makedirs(config.out_dir, exist_ok=True)\n",
        "  data_path = pathlib.Path(config.out_dir) / f'{split}.bin'\n",
        "  total_tokens = 0\n",
        "  with open(data_path, mode='wb') as f:\n",
        "    batch_tokens = []\n",
        "    for i, example in enumerate(tqdm(dataset)):\n",
        "      if i >= config.max_examples:\n",
        "        break\n",
        "      tokens = enc.encode_ordinary(example['text'])\n",
        "      batch_tokens.extend(tokens)\n",
        "      total_tokens += len(tokens)\n",
        "      if (i + 1) % config.write_batch_size == 0:\n",
        "        chunk = np.array(batch_tokens, dtype=np.uint16)\n",
        "        f.write(chunk.tobytes())\n",
        "        batch_tokens = []\n",
        "\n",
        "    if batch_tokens:\n",
        "      chunk = np.array(chunk, dtype=np.uint16)\n",
        "      f.write(chunk.tobytes())\n",
        "\n",
        "  print(f'Wrote {total_tokens=:,} to path: {str(data_path)}')\n"
      ],
      "metadata": {
        "id": "KS-Dh72w5-5m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DatasetConfig()\n",
        "pretokenize_and_save(config)"
      ],
      "metadata": {
        "id": "TjXdgfEE5-23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "0ada770966234be9a30bc14dd4bfb69c",
            "167492abf8104764b72aa13c53ffe7d7",
            "665bb838f9274e80b9350c6ab48585ee",
            "95eef6921a394806b0af5656b954f1b7",
            "9fb7f93f4d3945c98c9ca4cef1f94687",
            "7d3720f17136439fb2ca73ae7b1ca4eb",
            "941b595afde9440f92d62c2ea9f67f8c",
            "111008e8ab1c4dfc849e4d4ae8075acd",
            "341a9e54bff843a6b466f438515c41e8",
            "8b8f1b74cac24f55af2c225ccaf187f5",
            "f30363e74aa74636afb31fb606e9d5c3"
          ]
        },
        "outputId": "b6ba95f9-f516-45ff-9f63-c3ed1528b4fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ada770966234be9a30bc14dd4bfb69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "600000it [02:20, 4269.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote total_tokens=134,054,957 to path: data/train.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretokenize_and_save(config, split='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTY23WOnAayj",
        "outputId": "a7b3e790-8f54-459d-a529-77ed6e649502"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21990it [00:06, 3316.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote total_tokens=4,743,928 to path: data/validation.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenDataset(Dataset):\n",
        "  def __init__(self, config: DatasetConfig, split='train'):\n",
        "    super().__init__()\n",
        "    self.block_size = config.n_ctx\n",
        "    path = pathlib.Path(config.out_dir) / f'{split}.bin'\n",
        "    self.tokens = np.memmap(path, dtype=np.uint16, mode='r')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.tokens) // self.block_size\n",
        "\n",
        "  def __getitem__(self, index: int) -> Tuple[Tensor, Tensor]:\n",
        "    start = index * self.block_size\n",
        "    chunk = torch.from_numpy(\n",
        "        self.tokens[start: start+1+self.block_size].astype(np.int64)\n",
        "    )\n",
        "    x = chunk[:-1]\n",
        "    y = chunk[1:]\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "TeuMnj9j5-z1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TrainingConfig:\n",
        "  lr: float = 3e-5\n",
        "  log_steps: int = 200\n",
        "  max_iters: int = 100\n",
        "  train_batch_size: int = 8\n",
        "  val_batch_size: int = 4\n",
        "  out_path: str = './out'\n"
      ],
      "metadata": {
        "id": "eB5HXAnKBCCd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    model: GPT2Model,\n",
        "    loader: DataLoader,\n",
        "    max_batches: int = 20,\n",
        "    device:str='cuda') -> float:\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    enc = tiktoken.get_encoding('gpt2')\n",
        "    with torch.no_grad():\n",
        "      for i, (x, y) in enumerate(tqdm(loader)):\n",
        "        if i >= max_batches:\n",
        "          break\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, loss = model(x, targets=y)\n",
        "        losses.append(loss.item())\n",
        "        if i == 0:\n",
        "          preds = logits.argmax(dim=-1)\n",
        "          print(f'Input: {enc.decode(x[0].tolist())}\\nOutput: {enc.decode(preds[0].tolist())}')\n",
        "    return sum(losses) / len(losses)"
      ],
      "metadata": {
        "id": "wizkFen9DX1I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = GPT2Config()\n",
        "model = GPT2Model(config).to(device)\n",
        "data_config = DatasetConfig()\n",
        "train_dataset = TokenDataset(data_config, split='train')\n",
        "val_dataset = TokenDataset(data_config, split='validation')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: GPT2Model,\n",
        "    train_dataset: TokenDataset,\n",
        "    valid_dataset: TokenDataset,\n",
        "    train_config: TrainingConfig):\n",
        "\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=train_config.lr)\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=train_config.train_batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=4,\n",
        "      pin_memory=True\n",
        "  )\n",
        "\n",
        "  val_dataloader = DataLoader(\n",
        "      val_dataset,\n",
        "      batch_size=train_config.val_batch_size,\n",
        "      shuffle=False,\n",
        "      pin_memory=False\n",
        "  )\n",
        "\n",
        "  best_val_loss = float('inf')\n",
        "  best_model_path = pathlib.Path(train_config.out_path) / f'best_model.pt'\n",
        "  os.makedirs(train_config.out_path, exist_ok=True)\n",
        "\n",
        "  for epoch in range(train_config.max_iters):\n",
        "    model.train()\n",
        "    for step, (x, y) in enumerate(train_dataloader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      _, loss = model(x, targets=y)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      optimizer.step()\n",
        "\n",
        "      if step % train_config.log_steps == 0:\n",
        "        print(f'epoch {epoch:4} | step: {step:5d} | train_loss {loss.item():.4f}')\n",
        "\n",
        "\n",
        "    val_loss = evaluate(model, val_dataloader, max_batches=2000, device=device)\n",
        "    print(f'epoch: {epoch} | val loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      torch.save({\n",
        "          'epoch' : epoch,\n",
        "          'model' : model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'val_loss' : val_loss,\n",
        "          'model_config': config,\n",
        "          'data_config': data_config,\n",
        "          'train_config': train_config\n",
        "      }, best_model_path)"
      ],
      "metadata": {
        "id": "jOvBN4V65-xR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = TrainingConfig()\n",
        "train(model, train_dataset=train_dataset, valid_dataset=val_dataset, train_config=train_config)"
      ],
      "metadata": {
        "id": "X8IOh8Lb5-uV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bba3c04-b4fb-4fbd-9114-4256cc3da783"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch    0 | step:     0 | train_loss 10.8672\n",
            "epoch    0 | step:   200 | train_loss 4.7543\n",
            "epoch    0 | step:   400 | train_loss 4.2919\n",
            "epoch    0 | step:   600 | train_loss 4.1205\n",
            "epoch    0 | step:   800 | train_loss 3.8463\n",
            "epoch    0 | step:  1000 | train_loss 3.8636\n",
            "epoch    0 | step:  1200 | train_loss 3.4059\n",
            "epoch    0 | step:  1400 | train_loss 3.4324\n",
            "epoch    0 | step:  1600 | train_loss 3.4059\n",
            "epoch    0 | step:  1800 | train_loss 3.4817\n",
            "epoch    0 | step:  2000 | train_loss 3.1964\n",
            "epoch    0 | step:  2200 | train_loss 3.0764\n",
            "epoch    0 | step:  2400 | train_loss 3.0702\n",
            "epoch    0 | step:  2600 | train_loss 2.9180\n",
            "epoch    0 | step:  2800 | train_loss 3.0865\n",
            "epoch    0 | step:  3000 | train_loss 2.6199\n",
            "epoch    0 | step:  3200 | train_loss 2.7768\n",
            "epoch    0 | step:  3400 | train_loss 2.7093\n",
            "epoch    0 | step:  3600 | train_loss 2.7877\n",
            "epoch    0 | step:  3800 | train_loss 2.8743\n",
            "epoch    0 | step:  4000 | train_loss 2.7639\n",
            "epoch    0 | step:  4200 | train_loss 2.7605\n",
            "epoch    0 | step:  4400 | train_loss 2.5423\n",
            "epoch    0 | step:  4600 | train_loss 2.6480\n",
            "epoch    0 | step:  4800 | train_loss 2.6782\n",
            "epoch    0 | step:  5000 | train_loss 2.4164\n",
            "epoch    0 | step:  5200 | train_loss 2.5817\n",
            "epoch    0 | step:  5400 | train_loss 2.3830\n",
            "epoch    0 | step:  5600 | train_loss 2.4596\n",
            "epoch    0 | step:  5800 | train_loss 2.4962\n",
            "epoch    0 | step:  6000 | train_loss 2.3183\n",
            "epoch    0 | step:  6200 | train_loss 2.6343\n",
            "epoch    0 | step:  6400 | train_loss 2.3217\n",
            "epoch    0 | step:  6600 | train_loss 2.3415\n",
            "epoch    0 | step:  6800 | train_loss 2.3861\n",
            "epoch    0 | step:  7000 | train_loss 2.3711\n",
            "epoch    0 | step:  7200 | train_loss 2.2240\n",
            "epoch    0 | step:  7400 | train_loss 2.3557\n",
            "epoch    0 | step:  7600 | train_loss 2.2241\n",
            "epoch    0 | step:  7800 | train_loss 1.9983\n",
            "epoch    0 | step:  8000 | train_loss 2.1771\n",
            "epoch    0 | step:  8200 | train_loss 2.1780\n",
            "epoch    0 | step:  8400 | train_loss 2.0895\n",
            "epoch    0 | step:  8600 | train_loss 2.3186\n",
            "epoch    0 | step:  8800 | train_loss 2.2652\n",
            "epoch    0 | step:  9000 | train_loss 2.0469\n",
            "epoch    0 | step:  9200 | train_loss 2.2080\n",
            "epoch    0 | step:  9400 | train_loss 2.2749\n",
            "epoch    0 | step:  9600 | train_loss 2.0624\n",
            "epoch    0 | step:  9800 | train_loss 2.2771\n",
            "epoch    0 | step: 10000 | train_loss 2.1773\n",
            "epoch    0 | step: 10200 | train_loss 2.0818\n",
            "epoch    0 | step: 10400 | train_loss 1.9239\n",
            "epoch    0 | step: 10600 | train_loss 2.1989\n",
            "epoch    0 | step: 10800 | train_loss 1.9658\n",
            "epoch    0 | step: 11000 | train_loss 2.0957\n",
            "epoch    0 | step: 11200 | train_loss 2.0179\n",
            "epoch    0 | step: 11400 | train_loss 1.8112\n",
            "epoch    0 | step: 11600 | train_loss 1.8858\n",
            "epoch    0 | step: 11800 | train_loss 2.0028\n",
            "epoch    0 | step: 12000 | train_loss 2.1308\n",
            "epoch    0 | step: 12200 | train_loss 1.9914\n",
            "epoch    0 | step: 12400 | train_loss 2.0677\n",
            "epoch    0 | step: 12600 | train_loss 1.8563\n",
            "epoch    0 | step: 12800 | train_loss 1.7798\n",
            "epoch    0 | step: 13000 | train_loss 1.8533\n",
            "epoch    0 | step: 13200 | train_loss 2.0353\n",
            "epoch    0 | step: 13400 | train_loss 2.0131\n",
            "epoch    0 | step: 13600 | train_loss 1.6725\n",
            "epoch    0 | step: 13800 | train_loss 1.9525\n",
            "epoch    0 | step: 14000 | train_loss 1.9424\n",
            "epoch    0 | step: 14200 | train_loss 1.7583\n",
            "epoch    0 | step: 14400 | train_loss 1.8926\n",
            "epoch    0 | step: 14600 | train_loss 1.8120\n",
            "epoch    0 | step: 14800 | train_loss 2.0186\n",
            "epoch    0 | step: 15000 | train_loss 1.9006\n",
            "epoch    0 | step: 15200 | train_loss 1.9359\n",
            "epoch    0 | step: 15400 | train_loss 1.6987\n",
            "epoch    0 | step: 15600 | train_loss 2.0470\n",
            "epoch    0 | step: 15800 | train_loss 1.9062\n",
            "epoch    0 | step: 16000 | train_loss 1.8837\n",
            "epoch    0 | step: 16200 | train_loss 1.8130\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 3/1160 [00:00<01:54, 10.12it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\n",
            "\n",
            "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
            "\n",
            "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill and how she couldn't climb it. Billy said, \"I have an idea! Let's find some big leaves to put under your feet. They will help you climb the icy hill.\" Roxy and Billy looked for big leaves and found some. Roxy put the leaves under her feet and tried to climb the icy hill again.\n",
            "\n",
            "This time, Roxy didn't slip. She climbed and climbed until she reached the top of the icy hill. Roxy was so happy! She and Billy played on the icy hill all day. From that day on, Roxy and Billy were the best of friends, and they climbed and played together all the time. And Roxy learned that with a little help from a friend, she could climb anything.Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy.\n",
            "\n",
            "One day, Daisy saw a dog. The dog was big and had a name too. His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.\n",
            "\n",
            "Every day, Max would come to the yard to play. Daisy would watch and smile. They were very happy together. And even though Daisy was small, she knew that she had a big friend in Max.Once upon a time, there was a thoughtful girl named Sue. Sue loved to help her mom around the house. One day, her mom asked her to wipe the table after they ate their lunch. Sue was happy to help.\n",
            "\n",
            "As Sue was wiping the table, she saw a pretty candle on the window sill. The candle was her mom's favorite. Sue wanted to do something nice for her mom, so she said, \"Mom, can I light the candle for you?\" Her mom said, \"Yes, but be very careful.\"\n",
            "\n",
            "Sue carefully lit the candle and put it on the table. Her mom was so happy to see the pretty candle. They both sat and watched the candle burn. Sue's mom said, \"Thank you, Sue, for being so thoughtful and careful.\" Sue felt proud that she could help her mom.\n",
            "\n",
            "The moral of the story is to always be thoughtful and careful when helping others.Once upon a time, there was a kind farmer. He had a big cow. The cow was sad. The farmer did not know why.\n",
            "\n",
            "One day, a little boy came to the farm. He saw the sad cow. The boy kneeled down to talk to the cow. \"Why are you sad, cow?\" he asked. The cow said, \"I am lonely. I want a friend.\"\n",
            "\n",
            "The kind farmer heard the cow. He wanted to help. So, he got another cow to be friends with the sad cow. The sad cow was happy now. They played together every day. And the kind farmer, the little boy, and the two cows all lived happily ever after.Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. They loved to play together in the big green park near their house. One sunny day, they went to the park to play.\n",
            "\n",
            "While playing, Tom saw a big sour lemon on the ground. He wanted to play with it, but when he touched it, it started to roll away. Tom ran after the lemon, trying to catch it. But as he ran, Tom got lost in the park. Lucy looked around, but she could not find Tom. She was very sad.\n",
            "\n",
            "Lucy did not give up. She searched the park for her friend. At last, she found him near a big tree. Tom was trying to catch the lemon, but it vanished into a hole in the ground. Tom was happy to see Lucy again\n",
            "Output:  was He was a cat thing and wanted, \"Wow, that! that car is so pretty and pretty.\n",
            " was and said, \"Yes you, Spot! I love my so day.\"\n",
            "\n",
            "Spot a, the car, Kitty and Spot went happy. They went a big bottle to ducks water. Kitty drank some water and drank happy happy. They played with in day long had good friends.Once upon a time, in a small forest, there was a littleinoceros named Bobuf. Roxy was to play trees He would trees and and, and even. One day, Roxy saw a old tree. She wanted never seen it like it before.\n",
            " was very and pretty. and she wanted to go it.\n",
            "\n",
            "Roxy climbed to climb the hill hill, but she was too hard. She tried to and again, but she couldn going.. Sheoxy was sad, She wanted to climb the hill hill, badly. She, she saw a big bird. Lily. Billy was the heoxy was sad. asked, \"Why are you sad?\" littleoxy?\"\n",
            "\n",
            "Roxy said Billy about the icy hill. how he could't climb it. Billy said, \"Don can an idea! Let's climb a water rocks to climb on the feet and Maybe will be you.\" the hill hill.\" Sooxy was Billy worked around the leaves to found a leaves Theyoxy was the leaves on his feet. they to climb the hill hill..\n",
            "\n",
            "R time, Roxy and't give and She was the climbed until she reached the top. the hill hill. Sheoxy was so happy to She thanked Billy were in the icy hill all day long They that day on, Roxy and Billy were the best of friends. and they always the played together every day time.Once theyoxy was that sometimes a little help, her cold, he could do the sheOnce upon a time, there a small house, there was a little dogisy. The daisy was many big on The name was Lily. Daisy liked a pretty. but she liked very very small.\n",
            "\n",
            "One day, Daisy saw a big. The dog was big and brown a long.. Daisy name was Max. Daisy was to play with the yard. He wanted to play the play with\n",
            " liked Daisy played best.\n",
            "\n",
            "One day, Daisy and go to the yard and play with He would play Max play. She would very happy.. They they though Max was small, she could Max Max could a friend friend. the. Max upon a time, there was a little dog named Lily. Sue loved to play her mom in the house. One day, her mom asked her to help the dishes. dinner were. food. Sue did very to help her\n",
            "\n",
            "S they was cleaning the table, her saw a big flower on the table.. She candle was very mom's birthday toy Sue wanted to help something with for her mom. so she went, \"Mom, can I help the candle?\" you?\" Her mom smiled, \"Yes, Sue be careful careful.\n",
            "\n",
            "Sue went opened the candle and put it on her window. She mom was very proud to see the candle candle. She both smiled down watched the candle together. Sue was mom said, \"Good you, Sue. for helping so kind and helping with Sue smiled proud of she could help her mom andOnce\n",
            "From moral of the story is that always be kind and help when you others,Once upon a time, there was a little girl. He had a big farm named The cow was very because The farmer wanted not like what the He\n",
            "One day, the little girl came to the farm. The saw the cow cow. The farmer wantedeled down and the to the cow. TheHi are you sad?\" cow?\" the asked. The cow said, \"I am sad. I am to friend.\"\n",
            "\n",
            "The farmer farmer smiled the boy's He said to help the He, he said a cow. play his.. cow cow. The cow cow was not.. The all together all day.Once they farmer farmer was the cow boy, the the cow became became lived happily ever after.Once upon a time, there was a little girl named Lily. She loved a big cat named Mitt. Tom were to play together. the park, grass. their house.\n",
            " day day, they saw to the park to play.\n",
            "\n",
            "At they, they saw a big tree bug on the ground. He wanted to eat with it, but he he tried it, it made to shrink away. Lucy was after the lemon, but to get it.\n",
            " he he was, he tri very. the mud.\n",
            " was for and but she could not find Tom.\n",
            " was very sad.\n",
            "\n",
            "Thency saw not know up. She went high park, Tom mom, She the, she found Tom. the big tree. She was so to get the lemon, but he was. the big. the ground. Lucy was very and see her again.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1160/1160 [01:47<00:00, 10.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 | val loss: 1.8179\n",
            "epoch    1 | step:     0 | train_loss 1.6890\n",
            "epoch    1 | step:   200 | train_loss 1.8509\n",
            "epoch    1 | step:   400 | train_loss 2.0580\n",
            "epoch    1 | step:   600 | train_loss 1.8764\n",
            "epoch    1 | step:   800 | train_loss 1.7376\n",
            "epoch    1 | step:  1000 | train_loss 1.9256\n",
            "epoch    1 | step:  1200 | train_loss 1.9663\n",
            "epoch    1 | step:  1400 | train_loss 1.8613\n",
            "epoch    1 | step:  1600 | train_loss 1.7877\n",
            "epoch    1 | step:  1800 | train_loss 1.8273\n",
            "epoch    1 | step:  2000 | train_loss 1.7959\n",
            "epoch    1 | step:  2200 | train_loss 1.7887\n",
            "epoch    1 | step:  2400 | train_loss 1.9185\n",
            "epoch    1 | step:  2600 | train_loss 1.7561\n",
            "epoch    1 | step:  2800 | train_loss 1.7235\n",
            "epoch    1 | step:  3000 | train_loss 1.8207\n",
            "epoch    1 | step:  3200 | train_loss 1.6815\n",
            "epoch    1 | step:  3400 | train_loss 1.8177\n",
            "epoch    1 | step:  3600 | train_loss 1.8451\n",
            "epoch    1 | step:  3800 | train_loss 1.8381\n",
            "epoch    1 | step:  4000 | train_loss 1.8918\n",
            "epoch    1 | step:  4200 | train_loss 1.7610\n",
            "epoch    1 | step:  4400 | train_loss 1.8250\n",
            "epoch    1 | step:  4600 | train_loss 1.7966\n",
            "epoch    1 | step:  4800 | train_loss 1.9053\n",
            "epoch    1 | step:  5000 | train_loss 1.7515\n",
            "epoch    1 | step:  5200 | train_loss 1.8978\n",
            "epoch    1 | step:  5400 | train_loss 1.8902\n",
            "epoch    1 | step:  5600 | train_loss 1.6428\n",
            "epoch    1 | step:  5800 | train_loss 1.6934\n",
            "epoch    1 | step:  6000 | train_loss 1.7835\n",
            "epoch    1 | step:  6200 | train_loss 1.7451\n",
            "epoch    1 | step:  6400 | train_loss 1.8574\n",
            "epoch    1 | step:  6600 | train_loss 1.7564\n",
            "epoch    1 | step:  6800 | train_loss 1.9046\n",
            "epoch    1 | step:  7000 | train_loss 1.6890\n",
            "epoch    1 | step:  7200 | train_loss 1.7639\n",
            "epoch    1 | step:  7400 | train_loss 1.6103\n",
            "epoch    1 | step:  7600 | train_loss 1.7496\n",
            "epoch    1 | step:  7800 | train_loss 1.6882\n",
            "epoch    1 | step:  8000 | train_loss 1.6848\n",
            "epoch    1 | step:  8200 | train_loss 1.6687\n",
            "epoch    1 | step:  8400 | train_loss 1.7695\n",
            "epoch    1 | step:  8600 | train_loss 1.9208\n",
            "epoch    1 | step:  8800 | train_loss 1.8674\n",
            "epoch    1 | step:  9000 | train_loss 1.6581\n",
            "epoch    1 | step:  9200 | train_loss 1.7932\n",
            "epoch    1 | step:  9400 | train_loss 1.7711\n",
            "epoch    1 | step:  9600 | train_loss 1.7594\n",
            "epoch    1 | step:  9800 | train_loss 1.6592\n",
            "epoch    1 | step: 10000 | train_loss 1.6440\n",
            "epoch    1 | step: 10200 | train_loss 1.5631\n",
            "epoch    1 | step: 10400 | train_loss 1.8042\n",
            "epoch    1 | step: 10600 | train_loss 1.6981\n",
            "epoch    1 | step: 10800 | train_loss 1.5989\n",
            "epoch    1 | step: 11000 | train_loss 1.8172\n",
            "epoch    1 | step: 11200 | train_loss 1.7644\n",
            "epoch    1 | step: 11400 | train_loss 1.7860\n",
            "epoch    1 | step: 11600 | train_loss 1.5987\n",
            "epoch    1 | step: 11800 | train_loss 1.6080\n",
            "epoch    1 | step: 12000 | train_loss 1.5227\n",
            "epoch    1 | step: 12200 | train_loss 1.6634\n",
            "epoch    1 | step: 12400 | train_loss 1.7539\n",
            "epoch    1 | step: 12600 | train_loss 1.8504\n",
            "epoch    1 | step: 12800 | train_loss 1.5832\n",
            "epoch    1 | step: 13000 | train_loss 1.8126\n",
            "epoch    1 | step: 13200 | train_loss 1.5939\n",
            "epoch    1 | step: 13400 | train_loss 1.5528\n",
            "epoch    1 | step: 13600 | train_loss 1.7451\n",
            "epoch    1 | step: 13800 | train_loss 1.5520\n",
            "epoch    1 | step: 14000 | train_loss 1.5412\n",
            "epoch    1 | step: 14200 | train_loss 1.8012\n",
            "epoch    1 | step: 14400 | train_loss 1.5283\n",
            "epoch    1 | step: 14600 | train_loss 1.6017\n",
            "epoch    1 | step: 14800 | train_loss 1.6395\n",
            "epoch    1 | step: 15000 | train_loss 1.5024\n",
            "epoch    1 | step: 15200 | train_loss 1.7027\n",
            "epoch    1 | step: 15400 | train_loss 1.6614\n",
            "epoch    1 | step: 15600 | train_loss 1.7703\n",
            "epoch    1 | step: 15800 | train_loss 1.5871\n",
            "epoch    1 | step: 16000 | train_loss 1.5299\n",
            "epoch    1 | step: 16200 | train_loss 1.4290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/1160 [00:00<01:49, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\n",
            "\n",
            "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
            "\n",
            "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill and how she couldn't climb it. Billy said, \"I have an idea! Let's find some big leaves to put under your feet. They will help you climb the icy hill.\" Roxy and Billy looked for big leaves and found some. Roxy put the leaves under her feet and tried to climb the icy hill again.\n",
            "\n",
            "This time, Roxy didn't slip. She climbed and climbed until she reached the top of the icy hill. Roxy was so happy! She and Billy played on the icy hill all day. From that day on, Roxy and Billy were the best of friends, and they climbed and played together all the time. And Roxy learned that with a little help from a friend, she could climb anything.Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy.\n",
            "\n",
            "One day, Daisy saw a dog. The dog was big and had a name too. His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.\n",
            "\n",
            "Every day, Max would come to the yard to play. Daisy would watch and smile. They were very happy together. And even though Daisy was small, she knew that she had a big friend in Max.Once upon a time, there was a thoughtful girl named Sue. Sue loved to help her mom around the house. One day, her mom asked her to wipe the table after they ate their lunch. Sue was happy to help.\n",
            "\n",
            "As Sue was wiping the table, she saw a pretty candle on the window sill. The candle was her mom's favorite. Sue wanted to do something nice for her mom, so she said, \"Mom, can I light the candle for you?\" Her mom said, \"Yes, but be very careful.\"\n",
            "\n",
            "Sue carefully lit the candle and put it on the table. Her mom was so happy to see the pretty candle. They both sat and watched the candle burn. Sue's mom said, \"Thank you, Sue, for being so thoughtful and careful.\" Sue felt proud that she could help her mom.\n",
            "\n",
            "The moral of the story is to always be thoughtful and careful when helping others.Once upon a time, there was a kind farmer. He had a big cow. The cow was sad. The farmer did not know why.\n",
            "\n",
            "One day, a little boy came to the farm. He saw the sad cow. The boy kneeled down to talk to the cow. \"Why are you sad, cow?\" he asked. The cow said, \"I am lonely. I want a friend.\"\n",
            "\n",
            "The kind farmer heard the cow. He wanted to help. So, he got another cow to be friends with the sad cow. The sad cow was happy now. They played together every day. And the kind farmer, the little boy, and the two cows all lived happily ever after.Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. They loved to play together in the big green park near their house. One sunny day, they went to the park to play.\n",
            "\n",
            "While playing, Tom saw a big sour lemon on the ground. He wanted to play with it, but when he touched it, it started to roll away. Tom ran after the lemon, trying to catch it. But as he ran, Tom got lost in the park. Lucy looked around, but she could not find Tom. She was very sad.\n",
            "\n",
            "Lucy did not give up. She searched the park for her friend. At last, she found him near a big tree. Tom was trying to catch the lemon, but it vanished into a hole in the ground. Tom was happy to see Lucy again\n",
            "Output:  was He was Spot cat thing and wanted, \"Wow, that! that car is so pretty and pretty. Kitty smiled and said, \"Thank you, Spot!\" I like my so day.\"\n",
            "\n",
            "From they, Spot car, Spot and Spot went good. They went a big bottle to water water. Kitty drank some water and felt better happy. Kitty played with and day long became best friends.Once upon a time, there a small forest, there was a littleinoceros. Remyino. Roxy was to play trees He would trees and and, and even. R day, Roxy saw a old tree. She wanted never seen snow like it before.\n",
            " was very and pretty. and R wanted to climb it.\n",
            "\n",
            "Roxy climbed to climb the hill hill, but she was too hard. She slipped to and again, but she could falling.. Sheoxy was sad and She wanted to climb the icy hill, badly. She, she had a big bird named Tweet. Billy was R Roxy was sad and asked, \"Why are you sad, Roxy?\" R\n",
            "Roxy said Billy about the icy hill. how she wanted't climb it. Billy said, \"Don can an idea! Let's climb a shade rocks and make on the back.\" We will be you climb the icy hill.\"\n",
            "oxy and Billy worked around the leaves and found some big Theyoxy put the leaves on her feet and they to climb the icy hill.. She\n",
            "R time, Roxy and't give and She climbed the climbed until she reached the top. the hill hill. Sheoxy was so happy and She thanked Billy climbed in the icy hill all day long They that day on, Roxy and Billy always the best of friends. and they always the climbed together every day time.Once theyoxy was that sometimes a little help, her friend, she could do the.Once upon a time, there a small house, there lived a little boyisy. The daisy was many pretty. The name was Daisy. Daisy loved a happy. but she was very very small. She\n",
            "One day, Daisy saw a big. The dog was very and had a long.. Daisy name was Max. Daisy was to play with the yard. He wanted to play Max play.\n",
            " liked Daisy liked good.\n",
            "\n",
            "One day, Daisy would visit to the yard to play with He would watch Max Max. She would very happy together. They they though Max was small, she was Max Max could a friend friend like Max.Once upon a time, there was a little little named Lily. Sue loved to help her mom in the house. One day, Sue mom asked her to help the table. dinner finished the food. Sue did very to help.\n",
            "\n",
            "S they was wiping the table, she saw a big flower on the table.. She candle was very favorite's birthday color Sue wanted to help the special for her mom. so she went, \"Mom, can I help the candle?\" me?\" Her mom smiled, \"Yes, you be careful careful.\"\n",
            "\n",
            "Sue took wiped the candle and put it on the table. She mom was so proud and see the pretty candle. Sue both smiled down watched the candle together. Sue was mom said, \"Good you, Sue, for helping so thoughtful and helping.\" Sue smiled proud that she helped help her mom.Once\n",
            "From moral of the story is to always be kind and help when you others,Once upon a time, there was a little girl named He had a big farm named The cow was very because The farmer wanted not want how. He\n",
            "One day, the little girl came to the farm. He saw the cow cow. The boy wantedeled down and talk to the cow. TheWhy are you sad?\" cow?\" the asked. The cow said, \"I am sad because I want to friend.\"\n",
            "\n",
            "The boy farmer wanted the boy's He said to help the He, he said a cow. talk his.. cow cow. The cow cow was happy.. The played together and day.Once they cow farmer was the cow boy, and the cow were lived lived happily ever after.Once upon a time, there was a little girl named Lily. She loved a big dog named Fl. Tom loved to play together. the park yard yard. their house. One day day, Lucy went to the park to play.\n",
            "\n",
            "While they, Lucy saw a big, lemon on the ground. He wanted to eat with it, but Lucy he tried it, it made to shrink away. Lucy was after the lemon, but to get it. But the he ran, he tri caught. the park.\n",
            " was everywhere and but she could not find Tom.\n",
            " was very sad.\n",
            "\n",
            "Lucy's not give up. She went and park, Tom cat, She the, she found Tom under a big tree. She was so to get the lemon, but he was. the big. the ground. Lucy was very to see her again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1160/1160 [01:47<00:00, 10.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 | val loss: 1.5978\n",
            "epoch    2 | step:     0 | train_loss 1.4615\n",
            "epoch    2 | step:   200 | train_loss 1.6890\n",
            "epoch    2 | step:   400 | train_loss 1.5846\n",
            "epoch    2 | step:   600 | train_loss 1.6913\n",
            "epoch    2 | step:   800 | train_loss 1.6966\n",
            "epoch    2 | step:  1000 | train_loss 1.5864\n",
            "epoch    2 | step:  1200 | train_loss 1.5298\n",
            "epoch    2 | step:  1400 | train_loss 1.5734\n",
            "epoch    2 | step:  1600 | train_loss 1.5904\n",
            "epoch    2 | step:  1800 | train_loss 1.7103\n",
            "epoch    2 | step:  2000 | train_loss 1.5467\n",
            "epoch    2 | step:  2200 | train_loss 1.4878\n",
            "epoch    2 | step:  2400 | train_loss 1.4842\n",
            "epoch    2 | step:  2600 | train_loss 1.5420\n",
            "epoch    2 | step:  2800 | train_loss 1.6234\n",
            "epoch    2 | step:  3000 | train_loss 1.6033\n",
            "epoch    2 | step:  3200 | train_loss 1.7546\n",
            "epoch    2 | step:  3400 | train_loss 1.4086\n",
            "epoch    2 | step:  3600 | train_loss 1.6263\n",
            "epoch    2 | step:  3800 | train_loss 1.6853\n",
            "epoch    2 | step:  4000 | train_loss 1.5591\n",
            "epoch    2 | step:  4200 | train_loss 1.6005\n",
            "epoch    2 | step:  4400 | train_loss 1.8926\n",
            "epoch    2 | step:  4600 | train_loss 1.4185\n",
            "epoch    2 | step:  4800 | train_loss 1.6349\n",
            "epoch    2 | step:  5000 | train_loss 1.3380\n",
            "epoch    2 | step:  5200 | train_loss 1.6876\n",
            "epoch    2 | step:  5400 | train_loss 1.7718\n",
            "epoch    2 | step:  5600 | train_loss 1.4173\n",
            "epoch    2 | step:  5800 | train_loss 1.6560\n",
            "epoch    2 | step:  6000 | train_loss 1.6843\n",
            "epoch    2 | step:  6200 | train_loss 1.5893\n",
            "epoch    2 | step:  6400 | train_loss 1.6546\n",
            "epoch    2 | step:  6600 | train_loss 1.6523\n",
            "epoch    2 | step:  6800 | train_loss 1.5513\n",
            "epoch    2 | step:  7000 | train_loss 1.3917\n",
            "epoch    2 | step:  7200 | train_loss 1.5078\n",
            "epoch    2 | step:  7400 | train_loss 1.6213\n",
            "epoch    2 | step:  7600 | train_loss 1.5623\n",
            "epoch    2 | step:  7800 | train_loss 1.6296\n",
            "epoch    2 | step:  8000 | train_loss 1.6375\n",
            "epoch    2 | step:  8200 | train_loss 1.5110\n",
            "epoch    2 | step:  8400 | train_loss 1.5071\n",
            "epoch    2 | step:  8600 | train_loss 1.4456\n",
            "epoch    2 | step:  8800 | train_loss 1.4847\n",
            "epoch    2 | step:  9000 | train_loss 1.4805\n",
            "epoch    2 | step:  9200 | train_loss 1.8518\n",
            "epoch    2 | step:  9400 | train_loss 1.5882\n",
            "epoch    2 | step:  9600 | train_loss 1.7177\n",
            "epoch    2 | step:  9800 | train_loss 1.5978\n",
            "epoch    2 | step: 10000 | train_loss 1.7331\n",
            "epoch    2 | step: 10200 | train_loss 1.6526\n",
            "epoch    2 | step: 10400 | train_loss 1.6067\n",
            "epoch    2 | step: 10600 | train_loss 1.4300\n",
            "epoch    2 | step: 10800 | train_loss 1.5442\n",
            "epoch    2 | step: 11000 | train_loss 1.5847\n",
            "epoch    2 | step: 11200 | train_loss 1.6772\n",
            "epoch    2 | step: 11400 | train_loss 1.6368\n",
            "epoch    2 | step: 11600 | train_loss 1.5549\n",
            "epoch    2 | step: 11800 | train_loss 1.5993\n",
            "epoch    2 | step: 12000 | train_loss 1.5827\n",
            "epoch    2 | step: 12200 | train_loss 1.4898\n",
            "epoch    2 | step: 12400 | train_loss 1.4093\n",
            "epoch    2 | step: 12600 | train_loss 1.5575\n",
            "epoch    2 | step: 12800 | train_loss 1.5254\n",
            "epoch    2 | step: 13000 | train_loss 1.3576\n",
            "epoch    2 | step: 13200 | train_loss 1.6967\n",
            "epoch    2 | step: 13400 | train_loss 1.4861\n",
            "epoch    2 | step: 13600 | train_loss 1.3442\n",
            "epoch    2 | step: 13800 | train_loss 1.5555\n",
            "epoch    2 | step: 14000 | train_loss 1.4729\n",
            "epoch    2 | step: 14200 | train_loss 1.6182\n",
            "epoch    2 | step: 14400 | train_loss 1.4084\n",
            "epoch    2 | step: 14600 | train_loss 1.5613\n",
            "epoch    2 | step: 14800 | train_loss 1.5449\n",
            "epoch    2 | step: 15000 | train_loss 1.4826\n",
            "epoch    2 | step: 15200 | train_loss 1.7067\n",
            "epoch    2 | step: 15400 | train_loss 1.4150\n",
            "epoch    2 | step: 15600 | train_loss 1.7125\n",
            "epoch    2 | step: 15800 | train_loss 1.6491\n",
            "epoch    2 | step: 16000 | train_loss 1.4633\n",
            "epoch    2 | step: 16200 | train_loss 1.4590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/1160 [00:00<01:50, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\n",
            "\n",
            "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
            "\n",
            "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill and how she couldn't climb it. Billy said, \"I have an idea! Let's find some big leaves to put under your feet. They will help you climb the icy hill.\" Roxy and Billy looked for big leaves and found some. Roxy put the leaves under her feet and tried to climb the icy hill again.\n",
            "\n",
            "This time, Roxy didn't slip. She climbed and climbed until she reached the top of the icy hill. Roxy was so happy! She and Billy played on the icy hill all day. From that day on, Roxy and Billy were the best of friends, and they climbed and played together all the time. And Roxy learned that with a little help from a friend, she could climb anything.Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy.\n",
            "\n",
            "One day, Daisy saw a dog. The dog was big and had a name too. His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.\n",
            "\n",
            "Every day, Max would come to the yard to play. Daisy would watch and smile. They were very happy together. And even though Daisy was small, she knew that she had a big friend in Max.Once upon a time, there was a thoughtful girl named Sue. Sue loved to help her mom around the house. One day, her mom asked her to wipe the table after they ate their lunch. Sue was happy to help.\n",
            "\n",
            "As Sue was wiping the table, she saw a pretty candle on the window sill. The candle was her mom's favorite. Sue wanted to do something nice for her mom, so she said, \"Mom, can I light the candle for you?\" Her mom said, \"Yes, but be very careful.\"\n",
            "\n",
            "Sue carefully lit the candle and put it on the table. Her mom was so happy to see the pretty candle. They both sat and watched the candle burn. Sue's mom said, \"Thank you, Sue, for being so thoughtful and careful.\" Sue felt proud that she could help her mom.\n",
            "\n",
            "The moral of the story is to always be thoughtful and careful when helping others.Once upon a time, there was a kind farmer. He had a big cow. The cow was sad. The farmer did not know why.\n",
            "\n",
            "One day, a little boy came to the farm. He saw the sad cow. The boy kneeled down to talk to the cow. \"Why are you sad, cow?\" he asked. The cow said, \"I am lonely. I want a friend.\"\n",
            "\n",
            "The kind farmer heard the cow. He wanted to help. So, he got another cow to be friends with the sad cow. The sad cow was happy now. They played together every day. And the kind farmer, the little boy, and the two cows all lived happily ever after.Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. They loved to play together in the big green park near their house. One sunny day, they went to the park to play.\n",
            "\n",
            "While playing, Tom saw a big sour lemon on the ground. He wanted to play with it, but when he touched it, it started to roll away. Tom ran after the lemon, trying to catch it. But as he ran, Tom got lost in the park. Lucy looked around, but she could not find Tom. She was very sad.\n",
            "\n",
            "Lucy did not give up. She searched the park for her friend. At last, she found him near a big tree. Tom was trying to catch the lemon, but it vanished into a hole in the ground. Tom was happy to see Lucy again\n",
            "Output: , You was Spot ball thing and wanted, \"Wow, that! that car is so pretty and shiny. Kitty smiled and said, \"Thank you, Spot! I like my so day.\"\n",
            "\n",
            "From they with the shiny, Spot and Spot went very. They went a big pond and water water. Kitty drank the water and felt happy happy. Kitty knew with and day, became best friends.Once upon a time, there a small forest, there was a littleinoceros named Remyino. Roxy was to play trees One would trees, flowers, and even. R day, Roxy saw a o pond. She wanted never seen anything like it before.\n",
            " was very and pretty, and R wanted to climb it.\n",
            "\n",
            "Roxy started to climb the icy hill, but it was too hard. She slipped to and again, but she could falling.. Sheoxy was getting and She wanted to climb the icy hill, badly. But, she had a big bird on Ch. Billy was R Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill. how she wanted't climb it. Billy said, \"Don can an idea! Let's go a water rocks and help on!\" feet.\" Then will help you.\".\" icy hill.\" Sooxy and Billy worked around leaves leaves and found many big Theyoxy was them leaves on her feet and they to climb the icy hill.. This\n",
            "When time, sheoxy and't give. She climbed the climbed until she reached the top. the icy hill. Sheoxy was so happy and She thanked Billy played together the icy hill all day long They that day on, Roxy and Billy were the best of friends. and they always the climbed together every the time.Once theyoxy learned that sometimes a little help from her friend, she could do the.Once upon a time, there a small house, there was a little,isy. The daisy was many big. The name was Lily. Daisy loved a happy and but she was very very pretty.\n",
            "\n",
            "One day, Daisy met a big. The dog was very and brown a long.. Daisy name was Max. Max was to play with the yard. He wanted to play Max run.\n",
            " liked Daisy liked good.\n",
            "\n",
            "One day, Daisy would come to the yard. play. Daisy would run Max smile. Max would very happy together. And Max though Max was small, she was Max Max was a friend heart like Max.Once upon a time, there was a little little named Lily. Sue loved to help her mom in the house. One day, her mom asked her to help the table. she were. food. Sue was very to help.\n",
            "\n",
            "S Sue was wiping the table, she saw a little butterfly on the table.. She candle was so favorite's birthday color Sue wanted to touch the fun for her mom. so she asked, \"Mom, can I help the candle?\" you?\" Her mom smiled, \"Yes, you be careful careful.\n",
            "\n",
            "Sue took wiped the candle and put it on the table. She mom was so happy and see the pretty candle. Sue both smiled down enjoyed the pretty together. Sue felt mom said, \"Thank you, Sue, for helping so thoughtful and helping with Sue smiled proud and she could help her mom andOnce\n",
            "From moral of the story is to always be kind and help with helping others.Once upon a time, there was a little girl named He had a big farm named The cow was very because The farmer wanted not know how. He\n",
            "One day, the little girl came to the farm. He saw the cow cow. The boy wantedeled down and talk to the cow. TheWhy are you sad?\" cow?\" asked asked. The cow said, \"I am sad. I cannot to friend.\"\n",
            "\n",
            "The boy farmer wanted the boy and He kne to help the He, he kne a cow. talk happy.. cow cow. The cow cow was not.. The played together all day.Once they cow farmer was the cow boy, and the cow were were lived happily ever after.Once upon a time, there was a little girl named Lily. She loved a big dog named Fl. Tom loved to play together in the park park yard. their house. One day day, Lucy went to the park to play.\n",
            "\n",
            "At they, Lucy saw a big, apple on the ground. He wanted to eat with it, but Lucy he tried it, it made to shrink away. Lucy was after it lemon, but to get it. Lucy he he ran, he tri too in the mud.\n",
            " was everywhere, but she could not find Tom.\n",
            " was very sad and\n",
            "\n",
            "Thency's not give up. She kept high park, Tom cat, Finally last, she found Tom hiding a big tree. Tom was so to get the lemon, but he was. the bush. the ground. Lucy was very to see his again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1160/1160 [01:46<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2 | val loss: 1.5028\n",
            "epoch    3 | step:     0 | train_loss 1.5217\n",
            "epoch    3 | step:   200 | train_loss 1.4996\n",
            "epoch    3 | step:   400 | train_loss 1.4721\n",
            "epoch    3 | step:   600 | train_loss 1.4095\n",
            "epoch    3 | step:   800 | train_loss 1.4377\n",
            "epoch    3 | step:  1000 | train_loss 1.4539\n",
            "epoch    3 | step:  1200 | train_loss 1.5956\n",
            "epoch    3 | step:  1400 | train_loss 1.6113\n",
            "epoch    3 | step:  1600 | train_loss 1.6243\n",
            "epoch    3 | step:  1800 | train_loss 1.7765\n",
            "epoch    3 | step:  2000 | train_loss 1.4571\n",
            "epoch    3 | step:  2200 | train_loss 1.4983\n",
            "epoch    3 | step:  2400 | train_loss 1.3908\n",
            "epoch    3 | step:  2600 | train_loss 1.6217\n",
            "epoch    3 | step:  2800 | train_loss 1.7734\n",
            "epoch    3 | step:  3000 | train_loss 1.4773\n",
            "epoch    3 | step:  3200 | train_loss 1.4317\n",
            "epoch    3 | step:  3400 | train_loss 1.5083\n",
            "epoch    3 | step:  3600 | train_loss 1.6837\n",
            "epoch    3 | step:  3800 | train_loss 1.3481\n",
            "epoch    3 | step:  4000 | train_loss 1.5909\n",
            "epoch    3 | step:  4200 | train_loss 1.4300\n",
            "epoch    3 | step:  4400 | train_loss 1.3238\n",
            "epoch    3 | step:  4600 | train_loss 1.6949\n",
            "epoch    3 | step:  4800 | train_loss 1.6250\n",
            "epoch    3 | step:  5000 | train_loss 1.5389\n",
            "epoch    3 | step:  5200 | train_loss 1.6320\n",
            "epoch    3 | step:  5400 | train_loss 1.4651\n",
            "epoch    3 | step:  5600 | train_loss 1.4990\n",
            "epoch    3 | step:  5800 | train_loss 1.5472\n",
            "epoch    3 | step:  6000 | train_loss 1.4303\n",
            "epoch    3 | step:  6200 | train_loss 1.3584\n",
            "epoch    3 | step:  6400 | train_loss 1.6956\n",
            "epoch    3 | step:  6600 | train_loss 1.5092\n",
            "epoch    3 | step:  6800 | train_loss 1.7392\n",
            "epoch    3 | step:  7000 | train_loss 1.3730\n",
            "epoch    3 | step:  7200 | train_loss 1.4100\n",
            "epoch    3 | step:  7400 | train_loss 1.5251\n",
            "epoch    3 | step:  7600 | train_loss 1.5168\n",
            "epoch    3 | step:  7800 | train_loss 1.7204\n",
            "epoch    3 | step:  8000 | train_loss 1.6030\n",
            "epoch    3 | step:  8200 | train_loss 1.5149\n",
            "epoch    3 | step:  8400 | train_loss 1.4272\n",
            "epoch    3 | step:  8600 | train_loss 1.4169\n",
            "epoch    3 | step:  8800 | train_loss 1.3818\n",
            "epoch    3 | step:  9000 | train_loss 1.5402\n",
            "epoch    3 | step:  9200 | train_loss 1.4073\n",
            "epoch    3 | step:  9400 | train_loss 1.3537\n",
            "epoch    3 | step:  9600 | train_loss 1.3239\n",
            "epoch    3 | step:  9800 | train_loss 1.6213\n",
            "epoch    3 | step: 10000 | train_loss 1.4822\n",
            "epoch    3 | step: 10200 | train_loss 1.6026\n",
            "epoch    3 | step: 10400 | train_loss 1.7485\n",
            "epoch    3 | step: 10600 | train_loss 1.5221\n",
            "epoch    3 | step: 10800 | train_loss 1.6458\n",
            "epoch    3 | step: 11000 | train_loss 1.5545\n",
            "epoch    3 | step: 11200 | train_loss 1.4383\n",
            "epoch    3 | step: 11400 | train_loss 1.4716\n",
            "epoch    3 | step: 11600 | train_loss 1.3558\n",
            "epoch    3 | step: 11800 | train_loss 1.5688\n",
            "epoch    3 | step: 12000 | train_loss 1.6664\n",
            "epoch    3 | step: 12200 | train_loss 1.7296\n",
            "epoch    3 | step: 12400 | train_loss 1.6216\n",
            "epoch    3 | step: 12600 | train_loss 1.3140\n",
            "epoch    3 | step: 12800 | train_loss 1.4315\n",
            "epoch    3 | step: 13000 | train_loss 1.6792\n",
            "epoch    3 | step: 13200 | train_loss 1.3401\n",
            "epoch    3 | step: 13400 | train_loss 1.5749\n",
            "epoch    3 | step: 13600 | train_loss 1.5701\n",
            "epoch    3 | step: 13800 | train_loss 1.4060\n",
            "epoch    3 | step: 14000 | train_loss 1.4751\n",
            "epoch    3 | step: 14200 | train_loss 1.4153\n",
            "epoch    3 | step: 14400 | train_loss 1.3747\n",
            "epoch    3 | step: 14600 | train_loss 1.4356\n",
            "epoch    3 | step: 14800 | train_loss 1.5549\n",
            "epoch    3 | step: 15000 | train_loss 1.3916\n",
            "epoch    3 | step: 15200 | train_loss 1.3845\n",
            "epoch    3 | step: 15400 | train_loss 1.5056\n",
            "epoch    3 | step: 15600 | train_loss 1.5471\n",
            "epoch    3 | step: 15800 | train_loss 1.5467\n",
            "epoch    3 | step: 16000 | train_loss 1.4295\n",
            "epoch    3 | step: 16200 | train_loss 1.3316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/1160 [00:00<01:50, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\n",
            "\n",
            "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
            "\n",
            "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill and how she couldn't climb it. Billy said, \"I have an idea! Let's find some big leaves to put under your feet. They will help you climb the icy hill.\" Roxy and Billy looked for big leaves and found some. Roxy put the leaves under her feet and tried to climb the icy hill again.\n",
            "\n",
            "This time, Roxy didn't slip. She climbed and climbed until she reached the top of the icy hill. Roxy was so happy! She and Billy played on the icy hill all day. From that day on, Roxy and Billy were the best of friends, and they climbed and played together all the time. And Roxy learned that with a little help from a friend, she could climb anything.Once upon a time, in a small yard, there was a small daisy. The daisy had a name. Her name was Daisy. Daisy was very small, but she was also very happy.\n",
            "\n",
            "One day, Daisy saw a dog. The dog was big and had a name too. His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.\n",
            "\n",
            "Every day, Max would come to the yard to play. Daisy would watch and smile. They were very happy together. And even though Daisy was small, she knew that she had a big friend in Max.Once upon a time, there was a thoughtful girl named Sue. Sue loved to help her mom around the house. One day, her mom asked her to wipe the table after they ate their lunch. Sue was happy to help.\n",
            "\n",
            "As Sue was wiping the table, she saw a pretty candle on the window sill. The candle was her mom's favorite. Sue wanted to do something nice for her mom, so she said, \"Mom, can I light the candle for you?\" Her mom said, \"Yes, but be very careful.\"\n",
            "\n",
            "Sue carefully lit the candle and put it on the table. Her mom was so happy to see the pretty candle. They both sat and watched the candle burn. Sue's mom said, \"Thank you, Sue, for being so thoughtful and careful.\" Sue felt proud that she could help her mom.\n",
            "\n",
            "The moral of the story is to always be thoughtful and careful when helping others.Once upon a time, there was a kind farmer. He had a big cow. The cow was sad. The farmer did not know why.\n",
            "\n",
            "One day, a little boy came to the farm. He saw the sad cow. The boy kneeled down to talk to the cow. \"Why are you sad, cow?\" he asked. The cow said, \"I am lonely. I want a friend.\"\n",
            "\n",
            "The kind farmer heard the cow. He wanted to help. So, he got another cow to be friends with the sad cow. The sad cow was happy now. They played together every day. And the kind farmer, the little boy, and the two cows all lived happily ever after.Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. They loved to play together in the big green park near their house. One sunny day, they went to the park to play.\n",
            "\n",
            "While playing, Tom saw a big sour lemon on the ground. He wanted to play with it, but when he touched it, it started to roll away. Tom ran after the lemon, trying to catch it. But as he ran, Tom got lost in the park. Lucy looked around, but she could not find Tom. She was very sad.\n",
            "\n",
            "Lucy did not give up. She searched the park for her friend. At last, she found him near a big tree. Tom was trying to catch the lemon, but it vanished into a hole in the ground. Tom was happy to see Lucy again\n",
            "Output:  was He is a cat thing and wanted, \"Wow, that! that car is so pretty and shiny. Kitty smiled and said, \"Thank you, Spot! I love my every day.\"\n",
            "\n",
            "As playing with the shiny, Kitty and Spot went very. They went a big cup with water water. Kitty drank the water and felt happy happy. Kitty played with and day, had the friends.Once upon a time, there a small forest, there was a littleinoceros. Remyino. Roxy was to play trees She would trees, and, and even all One day, Roxy saw a unusual pond. She wanted never seen a like it before.\n",
            " was very and pretty. and R wanted to climb it.\n",
            "\n",
            "Roxy started to climb the icy hill, but it was too hard. She slipped to and again, but she could slipping down. Sheoxy was sad, She wanted to see the icy hill, badly. She, she had a big bird. Ch. Billy was R Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
            "\n",
            "Roxy told Billy about the icy hill. how she wanted't climb it. Billy said, \"Don can an idea! Let's play a ice rocks and help on the feet.\" Then will help you climb the icy hill.\" Sooxy and Billy went and leaves leaves and found big big Theyoxy put the leaves under her feet and started to climb the icy hill.. This\n",
            "When time, Roxy climbed't give and She climbed the climbed until she reached the top. the icy hill. Sheoxy was so happy! She thanked Billy played on the icy hill all day long From that day on, Roxy and Billy became the best of friends. and they always the played together every the time.Once theyoxy learned that sometimes a little help, her friend, she could do the sheOnce upon a time, there a small town, there was a little,isy. The daisy was many friend. The name was Daisy. Daisy was a happy, but she was very very smart.\n",
            "\n",
            "One day, Daisy met a big. The dog was very and scary a long.. Daisy name was Max. Max was to play with the yard. Daisy and to run Max run.\n",
            " would Daisy became good.\n",
            "\n",
            "Da day, Daisy would come to Daisy yard to play. Daisy would run Max talk. Max would very happy together. And they though Max was small, she was that Max could a friend heart like Max.Once upon a time, there was a little little named Lily. Sue loved to help her mom in the house. One day, her mom asked her to help the table. she finished. lunch. Sue was very to help.\n",
            "\n",
            "S Sue wiped wiping the table, she saw a big v on the table.. She candle was glowing favorite's favorite candle Sue wanted to help the special for her mom. so she asked, \"Mom, can I help the candle?\" you?\" Her mom smiled, \"Yes, you be careful careful.\"\n",
            "\n",
            "Sue lit wiped the candle and put it on the window. Her mom smiled very happy and see the candle candle. She both smiled down enjoyed the candle together. Sue felt mom said, \"Thank you, Sue, for being so thoughtful and helping with Sue smiled proud and she could help her mom.Once\n",
            "From moral of the story is to always be thoughtful and help with helping others.Once upon a time, there was a little girl named He had a big farm. The cow was very. The farmer wanted not know how the He\n",
            "One day, the little girl came to the farm. He saw the sad cow. The boy wantedeled down and say to the cow. TheWhy are you sad?\" cow?\" the asked. The cow said, \"I am sad. I want to friend to\n",
            "\n",
            "The boy farmer wanted the boy. He wanted to help the He, he kne up cow. talk happy.. little cow. The cow cow was happy.. The played together and day. The they cow farmer was the cow boy, and the cow cows were lived happily ever after.Once upon a time, there was a little girl named Lily. She loved a big cat named Fl. Tom loved to play together. the park yard yard. their house. One day day, Lucy found to the park to play.\n",
            "\n",
            "While they, Lucy saw a big, apple on the ground. He wanted to eat with it, but Lucy he tried it, it made to melt away. Lucy was after the lemon, but to catch it. He the he ran, he tri lost in the mud.\n",
            " was everywhere and but she could not find Tom.\n",
            " was very sad.\n",
            "\n",
            "Lucy's not give up. She kept high park and Tom cat Tom She last, she found Tom near a big tree. Tom was so to get the lemon, but he was. thin tiny. the tree. Lucy was very to find his,.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1160/1160 [01:46<00:00, 10.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3 | val loss: 1.4441\n",
            "epoch    4 | step:     0 | train_loss 1.3455\n",
            "epoch    4 | step:   200 | train_loss 1.5556\n",
            "epoch    4 | step:   400 | train_loss 1.3295\n",
            "epoch    4 | step:   600 | train_loss 1.4188\n",
            "epoch    4 | step:   800 | train_loss 1.4042\n",
            "epoch    4 | step:  1000 | train_loss 1.3990\n",
            "epoch    4 | step:  1200 | train_loss 1.3903\n",
            "epoch    4 | step:  1400 | train_loss 1.4777\n",
            "epoch    4 | step:  1600 | train_loss 1.4189\n",
            "epoch    4 | step:  1800 | train_loss 1.4376\n",
            "epoch    4 | step:  2000 | train_loss 1.3898\n",
            "epoch    4 | step:  2200 | train_loss 1.4327\n",
            "epoch    4 | step:  2400 | train_loss 1.5217\n",
            "epoch    4 | step:  2600 | train_loss 1.4153\n",
            "epoch    4 | step:  2800 | train_loss 1.4220\n",
            "epoch    4 | step:  3000 | train_loss 1.3315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHCv9WzM5-rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnYFmMmWGtld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8hKmNcxGtiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bcq47zzCGtf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJmXU9KfGtdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oweoi2UCGtah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WEaUwTIyGtXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GXJAL5RGtVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLV1NRnjGtSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ngEq_6vGtPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uth7imoIGtMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGOjGaioGtI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c43zWWNMGtGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}